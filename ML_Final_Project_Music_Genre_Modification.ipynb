{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Changing Music Genre Using Neural Style Transfer\n"
      ],
      "metadata": {
        "id": "wHWTM7llTVu9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "Music is an important part of many people's lives. It can lift you out of the darkest pits and also make you cry harderest. Artficial music has been popular for many years now and progress increases constantly. The object of this project was to try to change the genre of a song to another genre.\n",
        "\n",
        "It was through Neural Style Transfer that I discovered this concept and decided to try it myself.\n",
        "\n",
        "### What is Neural Style Transfer? \n",
        "\n",
        "Neural Style Transfer (NST) is the method of creating a new image with the content of one mage and the style of another. Essentially, the \"content\" image's style is changed to the style of another image, the \"style\" image. NST uses a deep CNN (Convolutional Neural Network) model to do this. The CNN extracts the main features of the images and uses them to create the new image.\n",
        "Normally a white noise image is first used as the template for the new image, and then the loss between the white noise image and the content image and between the white noise image and the style image is minimized through back-end propogation in order to preserve both images as much as possible without one overpowering the other in the final image.\n",
        "\n",
        "Based off of research into this topic, it seemed to be better to use the content image as the white noise image, so that only style loss needed to be taken into account rather than both style and content loss, which would be 0. \n",
        "Applying these concepts to music, the images we would be feeding our model would be the spectrograms of audio files, specifically mel spectrograms. A spectrogram is a 2-dimensional representation of a sound file. Spectrograms are multiple STFTs (short-time Fourier Transforms) over small intervals of the song. The Fourier transform expresses the loudness/aplitude of various frequencies over that interval, or another way to say it is that a spectrogram reveals the presence of certain frequencies within a file.  mel spectrogram is a spectrogram in which each unit of pitch sounds equally differen to the listener as it take into consideration most humans' inability to differentiate sounds with similar frequencies. By performing NST on the spectrograms and then converting those spectrgrams back into wav files, we have generated and can listen tot he new audio.\n"
      ],
      "metadata": {
        "id": "W7xYEioTVnhG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementation"
      ],
      "metadata": {
        "id": "CRTY5if4b7QY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we import all of the necessary libraries and modules to complete the Neural Style  Transfer. The dataset used was the [GTZAN Dataset - Music Genre Classification](https://www.kaggle.com/andradaolteanu/gtzan-dataset-music-genre-classification). It held 100 30-second-long files of ten different genres: blues, classical, country, disco, pop, hiphop, jazz, metal, pop, reggae, rock to make a total of 1000 song files. One of the files, 'jazz.00054.wav' had to be removed from the dataset though as it kept causing errors. Below is a snippet of the .csv that held information about the sound files. The only relevant information for this particular prject though were the filenames."
      ],
      "metadata": {
        "id": "SWx8RDZMb_mM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sn7ThREqPhe7"
      },
      "outputs": [],
      "source": [
        "#@title Import and Install Statements\n",
        "!pip install opendatasets\n",
        "!pip install pydub\n",
        "!pip install torchviz\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torchviz import make_dot\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
        "import numpy as np # we always love numpy\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import os, json, math, librosa\n",
        "import opendatasets as od\n",
        "\n",
        "import IPython.display as ipd\n",
        "import librosa.display\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "import sklearn.model_selection as sk\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras import layers\n",
        "from keras.layers import (Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, \n",
        "                          Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D)\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.initializers import glorot_uniform\n",
        "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np \n",
        "from sys import argv\n",
        "import torchvision.transforms as transforms\n",
        "import copy\n",
        "import librosa\n",
        "import soundfile as sf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "h81IH1ayfi7S",
        "outputId": "8f203c68-86bb-415e-ac4b-b480e9f18da7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>length</th>\n",
              "      <th>chroma_stft_mean</th>\n",
              "      <th>chroma_stft_var</th>\n",
              "      <th>rms_mean</th>\n",
              "      <th>rms_var</th>\n",
              "      <th>spectral_centroid_mean</th>\n",
              "      <th>spectral_centroid_var</th>\n",
              "      <th>spectral_bandwidth_mean</th>\n",
              "      <th>spectral_bandwidth_var</th>\n",
              "      <th>rolloff_mean</th>\n",
              "      <th>rolloff_var</th>\n",
              "      <th>zero_crossing_rate_mean</th>\n",
              "      <th>zero_crossing_rate_var</th>\n",
              "      <th>harmony_mean</th>\n",
              "      <th>harmony_var</th>\n",
              "      <th>perceptr_mean</th>\n",
              "      <th>perceptr_var</th>\n",
              "      <th>tempo</th>\n",
              "      <th>mfcc1_mean</th>\n",
              "      <th>mfcc1_var</th>\n",
              "      <th>mfcc2_mean</th>\n",
              "      <th>mfcc2_var</th>\n",
              "      <th>mfcc3_mean</th>\n",
              "      <th>mfcc3_var</th>\n",
              "      <th>mfcc4_mean</th>\n",
              "      <th>mfcc4_var</th>\n",
              "      <th>mfcc5_mean</th>\n",
              "      <th>mfcc5_var</th>\n",
              "      <th>mfcc6_mean</th>\n",
              "      <th>mfcc6_var</th>\n",
              "      <th>mfcc7_mean</th>\n",
              "      <th>mfcc7_var</th>\n",
              "      <th>mfcc8_mean</th>\n",
              "      <th>mfcc8_var</th>\n",
              "      <th>mfcc9_mean</th>\n",
              "      <th>mfcc9_var</th>\n",
              "      <th>mfcc10_mean</th>\n",
              "      <th>mfcc10_var</th>\n",
              "      <th>mfcc11_mean</th>\n",
              "      <th>mfcc11_var</th>\n",
              "      <th>mfcc12_mean</th>\n",
              "      <th>mfcc12_var</th>\n",
              "      <th>mfcc13_mean</th>\n",
              "      <th>mfcc13_var</th>\n",
              "      <th>mfcc14_mean</th>\n",
              "      <th>mfcc14_var</th>\n",
              "      <th>mfcc15_mean</th>\n",
              "      <th>mfcc15_var</th>\n",
              "      <th>mfcc16_mean</th>\n",
              "      <th>mfcc16_var</th>\n",
              "      <th>mfcc17_mean</th>\n",
              "      <th>mfcc17_var</th>\n",
              "      <th>mfcc18_mean</th>\n",
              "      <th>mfcc18_var</th>\n",
              "      <th>mfcc19_mean</th>\n",
              "      <th>mfcc19_var</th>\n",
              "      <th>mfcc20_mean</th>\n",
              "      <th>mfcc20_var</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>blues.00000.wav</td>\n",
              "      <td>661794</td>\n",
              "      <td>0.350088</td>\n",
              "      <td>0.088757</td>\n",
              "      <td>0.130228</td>\n",
              "      <td>0.002827</td>\n",
              "      <td>1784.165850</td>\n",
              "      <td>129774.064525</td>\n",
              "      <td>2002.449060</td>\n",
              "      <td>85882.761315</td>\n",
              "      <td>3805.839606</td>\n",
              "      <td>9.015054e+05</td>\n",
              "      <td>0.083045</td>\n",
              "      <td>0.000767</td>\n",
              "      <td>-4.529724e-05</td>\n",
              "      <td>0.008172</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.005698</td>\n",
              "      <td>123.046875</td>\n",
              "      <td>-113.570648</td>\n",
              "      <td>2564.207520</td>\n",
              "      <td>121.571793</td>\n",
              "      <td>295.913818</td>\n",
              "      <td>-19.168142</td>\n",
              "      <td>235.574432</td>\n",
              "      <td>42.366421</td>\n",
              "      <td>151.106873</td>\n",
              "      <td>-6.364664</td>\n",
              "      <td>167.934799</td>\n",
              "      <td>18.623499</td>\n",
              "      <td>89.180840</td>\n",
              "      <td>-13.704891</td>\n",
              "      <td>67.660492</td>\n",
              "      <td>15.343150</td>\n",
              "      <td>68.932579</td>\n",
              "      <td>-12.274110</td>\n",
              "      <td>82.204201</td>\n",
              "      <td>10.976572</td>\n",
              "      <td>63.386311</td>\n",
              "      <td>-8.326573</td>\n",
              "      <td>61.773094</td>\n",
              "      <td>8.803792</td>\n",
              "      <td>51.244125</td>\n",
              "      <td>-3.672300</td>\n",
              "      <td>41.217415</td>\n",
              "      <td>5.747995</td>\n",
              "      <td>40.554478</td>\n",
              "      <td>-5.162882</td>\n",
              "      <td>49.775421</td>\n",
              "      <td>0.752740</td>\n",
              "      <td>52.420910</td>\n",
              "      <td>-1.690215</td>\n",
              "      <td>36.524071</td>\n",
              "      <td>-0.408979</td>\n",
              "      <td>41.597103</td>\n",
              "      <td>-2.303523</td>\n",
              "      <td>55.062923</td>\n",
              "      <td>1.221291</td>\n",
              "      <td>46.936035</td>\n",
              "      <td>blues</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>blues.00001.wav</td>\n",
              "      <td>661794</td>\n",
              "      <td>0.340914</td>\n",
              "      <td>0.094980</td>\n",
              "      <td>0.095948</td>\n",
              "      <td>0.002373</td>\n",
              "      <td>1530.176679</td>\n",
              "      <td>375850.073649</td>\n",
              "      <td>2039.036516</td>\n",
              "      <td>213843.755497</td>\n",
              "      <td>3550.522098</td>\n",
              "      <td>2.977893e+06</td>\n",
              "      <td>0.056040</td>\n",
              "      <td>0.001448</td>\n",
              "      <td>1.395807e-04</td>\n",
              "      <td>0.005099</td>\n",
              "      <td>-0.000178</td>\n",
              "      <td>0.003063</td>\n",
              "      <td>67.999589</td>\n",
              "      <td>-207.501694</td>\n",
              "      <td>7764.555176</td>\n",
              "      <td>123.991264</td>\n",
              "      <td>560.259949</td>\n",
              "      <td>8.955127</td>\n",
              "      <td>572.810913</td>\n",
              "      <td>35.877647</td>\n",
              "      <td>264.506104</td>\n",
              "      <td>2.907320</td>\n",
              "      <td>279.932922</td>\n",
              "      <td>21.510466</td>\n",
              "      <td>156.477097</td>\n",
              "      <td>-8.560436</td>\n",
              "      <td>200.849182</td>\n",
              "      <td>23.370686</td>\n",
              "      <td>142.555954</td>\n",
              "      <td>-10.099661</td>\n",
              "      <td>166.108521</td>\n",
              "      <td>11.900497</td>\n",
              "      <td>104.358612</td>\n",
              "      <td>-5.555639</td>\n",
              "      <td>105.173630</td>\n",
              "      <td>5.376327</td>\n",
              "      <td>96.197212</td>\n",
              "      <td>-2.231760</td>\n",
              "      <td>64.914291</td>\n",
              "      <td>4.220140</td>\n",
              "      <td>73.152534</td>\n",
              "      <td>-6.012148</td>\n",
              "      <td>52.422142</td>\n",
              "      <td>0.927998</td>\n",
              "      <td>55.356403</td>\n",
              "      <td>-0.731125</td>\n",
              "      <td>60.314529</td>\n",
              "      <td>0.295073</td>\n",
              "      <td>48.120598</td>\n",
              "      <td>-0.283518</td>\n",
              "      <td>51.106190</td>\n",
              "      <td>0.531217</td>\n",
              "      <td>45.786282</td>\n",
              "      <td>blues</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>blues.00002.wav</td>\n",
              "      <td>661794</td>\n",
              "      <td>0.363637</td>\n",
              "      <td>0.085275</td>\n",
              "      <td>0.175570</td>\n",
              "      <td>0.002746</td>\n",
              "      <td>1552.811865</td>\n",
              "      <td>156467.643368</td>\n",
              "      <td>1747.702312</td>\n",
              "      <td>76254.192257</td>\n",
              "      <td>3042.260232</td>\n",
              "      <td>7.840345e+05</td>\n",
              "      <td>0.076291</td>\n",
              "      <td>0.001007</td>\n",
              "      <td>2.105576e-06</td>\n",
              "      <td>0.016342</td>\n",
              "      <td>-0.000019</td>\n",
              "      <td>0.007458</td>\n",
              "      <td>161.499023</td>\n",
              "      <td>-90.722595</td>\n",
              "      <td>3319.044922</td>\n",
              "      <td>140.446304</td>\n",
              "      <td>508.765045</td>\n",
              "      <td>-29.093889</td>\n",
              "      <td>411.781219</td>\n",
              "      <td>31.684334</td>\n",
              "      <td>144.090317</td>\n",
              "      <td>-13.984504</td>\n",
              "      <td>155.493759</td>\n",
              "      <td>25.764742</td>\n",
              "      <td>74.548401</td>\n",
              "      <td>-13.664875</td>\n",
              "      <td>106.981827</td>\n",
              "      <td>11.639934</td>\n",
              "      <td>106.574875</td>\n",
              "      <td>-11.783643</td>\n",
              "      <td>65.447945</td>\n",
              "      <td>9.718760</td>\n",
              "      <td>67.908859</td>\n",
              "      <td>-13.133803</td>\n",
              "      <td>57.781425</td>\n",
              "      <td>5.791199</td>\n",
              "      <td>64.480209</td>\n",
              "      <td>-8.907628</td>\n",
              "      <td>60.385151</td>\n",
              "      <td>-1.077000</td>\n",
              "      <td>57.711136</td>\n",
              "      <td>-9.229274</td>\n",
              "      <td>36.580986</td>\n",
              "      <td>2.451690</td>\n",
              "      <td>40.598766</td>\n",
              "      <td>-7.729093</td>\n",
              "      <td>47.639427</td>\n",
              "      <td>-1.816407</td>\n",
              "      <td>52.382141</td>\n",
              "      <td>-3.439720</td>\n",
              "      <td>46.639660</td>\n",
              "      <td>-2.231258</td>\n",
              "      <td>30.573025</td>\n",
              "      <td>blues</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>blues.00003.wav</td>\n",
              "      <td>661794</td>\n",
              "      <td>0.404785</td>\n",
              "      <td>0.093999</td>\n",
              "      <td>0.141093</td>\n",
              "      <td>0.006346</td>\n",
              "      <td>1070.106615</td>\n",
              "      <td>184355.942417</td>\n",
              "      <td>1596.412872</td>\n",
              "      <td>166441.494769</td>\n",
              "      <td>2184.745799</td>\n",
              "      <td>1.493194e+06</td>\n",
              "      <td>0.033309</td>\n",
              "      <td>0.000423</td>\n",
              "      <td>4.583644e-07</td>\n",
              "      <td>0.019054</td>\n",
              "      <td>-0.000014</td>\n",
              "      <td>0.002712</td>\n",
              "      <td>63.024009</td>\n",
              "      <td>-199.544205</td>\n",
              "      <td>5507.517090</td>\n",
              "      <td>150.090897</td>\n",
              "      <td>456.505402</td>\n",
              "      <td>5.662678</td>\n",
              "      <td>257.161163</td>\n",
              "      <td>26.859079</td>\n",
              "      <td>158.267303</td>\n",
              "      <td>1.771399</td>\n",
              "      <td>268.034393</td>\n",
              "      <td>14.234031</td>\n",
              "      <td>126.794128</td>\n",
              "      <td>-4.832006</td>\n",
              "      <td>155.912079</td>\n",
              "      <td>9.286494</td>\n",
              "      <td>81.273743</td>\n",
              "      <td>-0.759186</td>\n",
              "      <td>92.114090</td>\n",
              "      <td>8.137607</td>\n",
              "      <td>71.314079</td>\n",
              "      <td>-3.200653</td>\n",
              "      <td>110.236687</td>\n",
              "      <td>6.079319</td>\n",
              "      <td>48.251999</td>\n",
              "      <td>-2.480174</td>\n",
              "      <td>56.799400</td>\n",
              "      <td>-1.079305</td>\n",
              "      <td>62.289902</td>\n",
              "      <td>-2.870789</td>\n",
              "      <td>51.651592</td>\n",
              "      <td>0.780874</td>\n",
              "      <td>44.427753</td>\n",
              "      <td>-3.319597</td>\n",
              "      <td>50.206673</td>\n",
              "      <td>0.636965</td>\n",
              "      <td>37.319130</td>\n",
              "      <td>-0.619121</td>\n",
              "      <td>37.259739</td>\n",
              "      <td>-3.407448</td>\n",
              "      <td>31.949339</td>\n",
              "      <td>blues</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>blues.00004.wav</td>\n",
              "      <td>661794</td>\n",
              "      <td>0.308526</td>\n",
              "      <td>0.087841</td>\n",
              "      <td>0.091529</td>\n",
              "      <td>0.002303</td>\n",
              "      <td>1835.004266</td>\n",
              "      <td>343399.939274</td>\n",
              "      <td>1748.172116</td>\n",
              "      <td>88445.209036</td>\n",
              "      <td>3579.757627</td>\n",
              "      <td>1.572978e+06</td>\n",
              "      <td>0.101461</td>\n",
              "      <td>0.001954</td>\n",
              "      <td>-1.756129e-05</td>\n",
              "      <td>0.004814</td>\n",
              "      <td>-0.000010</td>\n",
              "      <td>0.003094</td>\n",
              "      <td>135.999178</td>\n",
              "      <td>-160.337708</td>\n",
              "      <td>5195.291992</td>\n",
              "      <td>126.219635</td>\n",
              "      <td>853.784729</td>\n",
              "      <td>-35.587811</td>\n",
              "      <td>333.792938</td>\n",
              "      <td>22.148071</td>\n",
              "      <td>193.456100</td>\n",
              "      <td>-32.478600</td>\n",
              "      <td>336.276825</td>\n",
              "      <td>10.852294</td>\n",
              "      <td>134.831573</td>\n",
              "      <td>-23.352329</td>\n",
              "      <td>93.257095</td>\n",
              "      <td>0.498434</td>\n",
              "      <td>124.672127</td>\n",
              "      <td>-11.793437</td>\n",
              "      <td>130.073349</td>\n",
              "      <td>1.207256</td>\n",
              "      <td>99.675575</td>\n",
              "      <td>-13.088418</td>\n",
              "      <td>80.254066</td>\n",
              "      <td>-2.813867</td>\n",
              "      <td>86.430626</td>\n",
              "      <td>-6.933385</td>\n",
              "      <td>89.555443</td>\n",
              "      <td>-7.552725</td>\n",
              "      <td>70.943336</td>\n",
              "      <td>-9.164666</td>\n",
              "      <td>75.793404</td>\n",
              "      <td>-4.520576</td>\n",
              "      <td>86.099236</td>\n",
              "      <td>-5.454034</td>\n",
              "      <td>75.269707</td>\n",
              "      <td>-0.916874</td>\n",
              "      <td>53.613918</td>\n",
              "      <td>-4.404827</td>\n",
              "      <td>62.910812</td>\n",
              "      <td>-11.703234</td>\n",
              "      <td>55.195160</td>\n",
              "      <td>blues</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          filename  length  chroma_stft_mean  ...  mfcc20_mean  mfcc20_var  label\n",
              "0  blues.00000.wav  661794          0.350088  ...     1.221291   46.936035  blues\n",
              "1  blues.00001.wav  661794          0.340914  ...     0.531217   45.786282  blues\n",
              "2  blues.00002.wav  661794          0.363637  ...    -2.231258   30.573025  blues\n",
              "3  blues.00003.wav  661794          0.404785  ...    -3.407448   31.949339  blues\n",
              "4  blues.00004.wav  661794          0.308526  ...   -11.703234   55.195160  blues\n",
              "\n",
              "[5 rows x 60 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@title Read Pandas Dataframe (removed jazz.00054.wav)\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/kaggle/gtzan-dataset-music-genre-classification/Data/features_30_sec.csv\")\n",
        "df = df.drop([554])\n",
        "#df = df.drop([5532, 5533, 5534, 5535, 5536, 5537, 5538, 5539, 5540, 5541])\n",
        "#filenames = df[\"filename\"]\n",
        "filenames = df[\"filename\"]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "x625TetHDtpO"
      },
      "outputs": [],
      "source": [
        "#@title Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "root_path = 'gdrive/MyDrive/kaggle/'  #change dir to your project folder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Model\n",
        "\n",
        "First, we start witht the CNN model that draws the features form the content and style spectrogram images to generate the new spectrogram image. Its layers are a 1-Dimensional convolutional layer followed by a ReLu activation function for limiting exponential growth of memory, followed by a pooling layer to reduce processing time, a neural network layer, another ReLu function, and a final neural network layer.\n",
        "\n",
        "Acording to [Intel](https://www.intel.com/content/www/us/en/developer/articles/technical/neural-style-transfer-on-audio-signals.html) Gram Matrix function is \"the inner product between the feature maps i and j represented by vectors in layer l and Nl is the number of feature maps.\" Essentially, it captures the essence of the style image and is used to calculate the style loss of the generated image in the Style Loss function. \n",
        "\n",
        "\n",
        "\n",
        "Most of this code came from or was inspired by the example program from [this repository](https://github.com/alishdipani/Neural-Style-Transfer-Audio).\n",
        "\n"
      ],
      "metadata": {
        "id": "ng45nj7Afi1p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hxtfrVhgUuwf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7238b12a-4e18-4f87-e477-54e143d486b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampling Rates are same\n",
            "Building the style transfer model..\n",
            "Optimizing..\n",
            "run [100]:\n",
            "Style Loss : 0.002846\n",
            "\n",
            "run [200]:\n",
            "Style Loss : 0.002839\n",
            "\n",
            "run [300]:\n",
            "Style Loss : 0.002835\n",
            "\n",
            "run [400]:\n",
            "Style Loss : 0.002822\n",
            "\n",
            "run [500]:\n",
            "Style Loss : 0.002796\n",
            "\n",
            "run [600]:\n",
            "Style Loss : 0.002771\n",
            "\n",
            "run [700]:\n",
            "Style Loss : 0.002756\n",
            "\n",
            "run [800]:\n",
            "Style Loss : 0.002748\n",
            "\n",
            "run [900]:\n",
            "Style Loss : 0.002744\n",
            "\n",
            "run [1000]:\n",
            "Style Loss : 0.002741\n",
            "\n",
            "DONE...\n"
          ]
        }
      ],
      "source": [
        "#@title Neural Style Transfer\n",
        "\n",
        "\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "\t\tdef __init__(self):\n",
        "\t\t\tsuper(CNNModel, self).__init__()\n",
        "\t\t\tself.cnn1 = nn.Conv1d(in_channels=1025, out_channels=4096, kernel_size=3, stride=1, padding=1)\n",
        "\t\t\tself.nl1 = nn.ReLU()\n",
        "\t\t\tself.pool1 = nn.AvgPool1d(kernel_size=5)\n",
        "\t\t\tself.fc1 = nn.Linear(4096*2500,2**5)\n",
        "\t\t\tself.nl3 = nn.ReLU()\n",
        "\t\t\tself.fc2 = nn.Linear(2**10,2**5)\n",
        "\t\t\n",
        "\t\tdef forward(self, x):\n",
        "\t\t\tout = self.cnn1(x)\n",
        "\t\t\tout = self.nl1(out)\n",
        "\t\t\tout = self.pool1(out)\n",
        "\t\t\tout = out.view(out.size(0),-1)\n",
        "\t\t\tout = self.fc1(out)\n",
        "\t\t\tout = self.nl3(out)\n",
        "\t\t\tout = self.fc2(out)\n",
        "\t\t\treturn out\n",
        "\n",
        "\n",
        "class GramMatrix(nn.Module):\n",
        "\n",
        "\tdef forward(self, input):\n",
        "\t\ta, b, c = input.size()  # a=batch size(=1)\n",
        "        # b=number of feature maps\n",
        "        # (c,d)=dimensions of a f. map (N=c*d)\n",
        "\t\tfeatures = input.view(a * b, c)  # resise F_XL into \\hat F_XL\n",
        "\t\tG = torch.mm(features, features.t())  # compute the gram product\n",
        "        # we 'normalize' the values of the gram matrix\n",
        "        # by dividing by the number of element in each feature maps.\n",
        "\t\treturn G.div(a * b * c)\n",
        "\n",
        "\n",
        "class StyleLoss(nn.Module):\n",
        "\n",
        "\tdef __init__(self, target, weight):\n",
        "\t\tsuper(StyleLoss, self).__init__()\n",
        "\t\tself.target = target.detach() * weight\n",
        "\t\tself.weight = weight\n",
        "\t\tself.gram = GramMatrix()\n",
        "\t\tself.criterion = nn.MSELoss()\n",
        "\n",
        "\tdef forward(self, input):\n",
        "\t\tself.output = input.clone()\n",
        "\t\tself.G = self.gram(input)\n",
        "\t\tself.G.mul_(self.weight)\n",
        "\t\tself.loss = self.criterion(self.G, self.target)\n",
        "\t\treturn self.output\n",
        "\n",
        "\tdef backward(self,retain_graph=True):\n",
        "\t\tself.loss.backward(retain_graph=retain_graph)\n",
        "\t\treturn self.loss\n",
        "\n",
        "\n",
        "#print('Enter the names of SCRIPT, Content audio, Style audio')\n",
        "# script, content_audio_name , style_audio_name = argv\n",
        "\n",
        "content_audio_name = \"/content/drive/MyDrive/kaggle/gtzan-dataset-music-genre-classification/Data/genres_original/blues/blues.00003.wav\"\n",
        "style_audio_name = \"/content/drive/MyDrive/kaggle/gtzan-dataset-music-genre-classification/Data/genres_original/country/country.00084.wav\"\n",
        "# USING LIBROSA\n",
        "N_FFT=2048\n",
        "def read_audio_spectum(filename):\n",
        "  x, fs = librosa.load(filename, duration=58.04) # Duration=58.05 so as to make sizes convenient\n",
        "  S = librosa.stft(x, N_FFT)\n",
        "  p = np.angle(S)\n",
        "  S = np.log1p(np.abs(S))  \n",
        "  return S, fs\n",
        "\n",
        "style_audio, style_sr = read_audio_spectum(style_audio_name)\n",
        "content_audio, content_sr = read_audio_spectum(content_audio_name)\n",
        "\n",
        "if(content_sr == style_sr):\n",
        "  print('Sampling Rates are same')\n",
        "else:\n",
        "  print('Sampling rates are not same')\n",
        "  exit()\n",
        "\n",
        "num_samples=style_audio.shape[1]\t\n",
        "  \n",
        "style_audio = style_audio.reshape([1,1025,num_samples])\n",
        "content_audio = content_audio.reshape([1,1025,num_samples])\n",
        "\n",
        "\n",
        "\n",
        "style_float = Variable(torch.from_numpy(style_audio))\n",
        "content_float = Variable(torch.from_numpy(content_audio))\n",
        "\n",
        "\n",
        "cnn = CNNModel()\n",
        "#if torch.cuda.is_available():\n",
        "  #cnn = cnn.cuda()\n",
        "style_layers_default = ['conv_1']\n",
        "\n",
        "style_weight=2500\n",
        "\n",
        "def get_style_model_and_losses(cnn, style_float,style_weight=style_weight, style_layers=style_layers_default): #STYLE WEIGHT\n",
        "  \n",
        "  cnn = copy.deepcopy(cnn)\n",
        "  style_losses = []\n",
        "  model = nn.Sequential()  # the new Sequential module network\n",
        "  gram = GramMatrix()  # we need a gram module in order to compute style targets\n",
        "  if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    gram = gram.cuda()\n",
        "\n",
        "  name = 'conv_1'\n",
        "  model.add_module(name, cnn.cnn1)\n",
        "  if name in style_layers:\n",
        "    target_feature = model(style_float).clone()\n",
        "    target_feature_gram = gram(target_feature)\n",
        "    style_loss = StyleLoss(target_feature_gram, style_weight)\n",
        "    model.add_module(\"style_loss_1\", style_loss)\n",
        "    style_losses.append(style_loss)\n",
        "\n",
        " \n",
        "  return model, style_losses\n",
        "\n",
        "\n",
        "input_float = content_float.clone()\n",
        "#input_float = Variable(torch.randn(content_float.size())).type(torch.FloatTensor)\n",
        "\n",
        "learning_rate_initial = 0.03\n",
        "\n",
        "def get_input_param_optimizer(input_float):\n",
        "  input_param = nn.Parameter(input_float.data)\n",
        "  #optimizer = optim.Adagrad([input_param], lr=learning_rate_initial, lr_decay=0.0001,weight_decay=0)\n",
        "  optimizer = optim.Adam([input_param], lr=learning_rate_initial, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
        "  return input_param, optimizer\n",
        "\n",
        "num_steps= 1000\n",
        "\n",
        "def run_style_transfer(cnn, style_float, input_float, num_steps=num_steps, style_weight=style_weight): #STYLE WEIGHT, NUM_STEPS\n",
        "  print('Building the style transfer model..')\n",
        "  model, style_losses= get_style_model_and_losses(cnn, style_float, style_weight)\n",
        "  input_param, optimizer = get_input_param_optimizer(input_float)\n",
        "  print('Optimizing..')\n",
        "  run = [0]\n",
        "\n",
        "  while run[0] <= num_steps:\n",
        "    def closure():\n",
        "            # correct the values of updated input image\n",
        "      input_param.data.clamp_(0, 1)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      model(input_param)\n",
        "      style_score = 0\n",
        "\n",
        "      for sl in style_losses:\n",
        "        #print('sl is ',sl,' style loss is ',style_score)\n",
        "        style_score += sl.backward()\n",
        "\n",
        "      run[0] += 1\n",
        "      if run[0] % 100 == 0:\n",
        "        print(\"run {}:\".format(run))\n",
        "        print('Style Loss : {:8f}'.format(style_score.data)) #CHANGE 4->8 \n",
        "        print()\n",
        "\n",
        "      return style_score\n",
        "\n",
        "\n",
        "    optimizer.step(closure)\n",
        "  input_param.data.clamp_(0, 1)\n",
        "  return input_param.data\n",
        "  \n",
        "output = run_style_transfer(cnn, style_float, input_float)\n",
        "\n",
        "\n",
        "output = output.squeeze(0)\n",
        "output = output.numpy()\n",
        "\n",
        "N_FFT=2048\n",
        "a = np.zeros_like(output)\n",
        "a = np.exp(output) - 1\n",
        "\n",
        "# This code is supposed to do phase reconstruction\n",
        "p = 2 * np.pi * np.random.random_sample(a.shape) - np.pi\n",
        "for i in range(500):\n",
        "  S = a * np.exp(1j*p)\n",
        "  x = librosa.istft(S)\n",
        "  p = np.angle(librosa.stft(x, N_FFT))\n",
        "\n",
        "OUTPUT_FILENAME = 'test_output2_2500.wav'\n",
        "sf.write(OUTPUT_FILENAME, x, style_sr, 'PCM_24')\n",
        "print('DONE...')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of generated songs from our Neural Style Transfer were few due to extreme time (the program took hours to run) and storage constraints (free Google Colab is very limiting). The main example I will be focusing on was the \"successful\" (the code *technically* works) conversion of a 30 second blues song into a 30 second country song.\n",
        "\n"
      ],
      "metadata": {
        "id": "gIKK-FjihRUI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the blues [song](https://drive.google.com/file/d/10ascZb-V5F3zHC8H83mWQp70orgEB420/view?usp=sharing). Linked for your convenience."
      ],
      "metadata": {
        "id": "7j2nuu7im-Mj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_path = \"/content/drive/MyDrive/kaggle/gtzan-dataset-music-genre-classification/Data/genres_original/blues/blues.00003.wav\"\n",
        "x , sr = librosa.load(audio_path)\n",
        "\n",
        "librosa.load(audio_path, sr=None)\n",
        "\n",
        "ipd.Audio(audio_path)\n",
        "\n",
        "plt.figure(figsize=(16, 5))\n",
        "librosa.display.waveplot(x, sr=sr)"
      ],
      "metadata": {
        "id": "jJgXZ50GkwiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the country [song](https://drive.google.com/file/d/1MhJdSB0g4K3FacuZiWmdbpb4AjrbKX0w/view?usp=sharing). Linked for your convenience."
      ],
      "metadata": {
        "id": "EPHKyF5Zler8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_path = \"/content/drive/MyDrive/kaggle/gtzan-dataset-music-genre-classification/Data/genres_original/country/country.00084.wav\"\n",
        "x , sr = librosa.load(audio_path)\n",
        "\n",
        "librosa.load(audio_path, sr=None)\n",
        "\n",
        "ipd.Audio(audio_path)\n",
        "\n",
        "plt.figure(figsize=(16, 5))\n",
        "librosa.display.waveplot(x, sr=sr)"
      ],
      "metadata": {
        "id": "4n1QpX1glWhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And this was the resulting [song](https://drive.google.com/file/d/1BbuPACdp8MPgXV9Txl2Q1HzruXOEahVh/view?usp=sharing), with the Neural Transfer Analysis run with 2500 steps. Linked for your convenience. As you can hear, it sounds terrible, to be frank. I was surprised that neither of the voices in both songs could be found in the generated audio and that the beat would be so choppy. The few iterations I was able to do were increase the steps to 3000 and add an additional convolutinal layer to the CNN, however these produced minimal improvements.\n",
        "\n"
      ],
      "metadata": {
        "id": "Z0As8ROkl4sw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "\n",
        "I believe the issue with the poor quality of the generated audio lay in the reconstruction of the modified spectrogram back into a wave file. I knew that the spectrogram did not contain all the information necessary to recontruct a decent song, however I had researched this issue and believe that the code for phase reconstruction in the \"Neural Style Transfer\" code block would fix the problem. Evidently this is not the case, but one thing I did learn is that\n",
        "\n",
        "It was extremely difficult to make iterations and try to improve this model. Not because it was too complicated or finicky, but because of time. On both the CPU and GPU, this algorithm took a very, very long time to run (about 2.5 to 3 hrs each time with a parameter of num_steps = 2500. The recommended amount of steps according to the code's source from [Intel](https://www.intel.com/content/www/us/en/developer/articles/technical/neural-style-transfer-on-audio-signals.html). This, coupled with the extremely limited usage of Google Colab (limited GPU and RunTime in particular). Having a limit on max runtime before the the colab forcefully stopped running made it difficult to do large chunks of data processing conveniently overnight for example, as even if the screen was kept on"
      ],
      "metadata": {
        "id": "niYp2HtAj0M2"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ML_Final_Project_Music_Genre_Modification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}